\documentclass[a4paper,11pt]{book}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{graphicx}
\usepackage{exsheets}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{filecontents}
\usepackage{multirow}
%\usepackage{showframe}% to show frames

\graphicspath{{images/}} 

\def\BState{\State\hskip-\ALG@thistlm}


\definecolor{TitleColor}{rgb}{0.65,0.04,0.07}
\definecolor{NumberColor}{rgb}{0.02,0.04,0.48}

\DeclareInstance{exsheets-heading}{fancy}{default}{
toc-reversed = true ,
indent-first = true ,
vscale = 2 ,
pre-code = \IfInsideQuestionT{\rule{\linewidth}{1pt}} ,
post-code =\IfInsideQuestionT{\rule{\linewidth}{1pt}} ,
subtitle-format = \large\scshape\color{rgb:red,0.65;green,0.04;blue,0.07} ,
number-format = \large\bfseries\color{rgb:red,0.02;green,0.04;blue,0.48} ,
points-format = \itshape ,
join = { number[r,B]title[l,B](.333em,0pt);
title[r,B]subtitle[l,B](1em,0pt)
} ,
attach =
{
main[hc,vc]number[hc,vc](0pt,0pt) ;
main[l,vc]subtitle[hc,vc](\marginparsep,0pt)
}
}



\DeclareInstance{exsheets-heading}{block-subtitle}{default}{
vscale = 2 ,
pre-code = \rule{\linewidth}{1pt} ,
post-code = \rule{\linewidth}{1pt} ,%title-format = \large\scshape\color{TitleColor} ,
number-format = \large\bfseries\color{rgb:red,0.02;green,0.04;blue,0.48} ,
subtitle-format = \large\scshape\color{black} ,
join = {
title[r,B]number[l,B](.333em,0pt) ;
title[r,B]subtitle[l,B](1em,0pt)
} ,
attach = {
main[l,vc]title[l,vc](0pt,0pt) ;
main[r,vc]points[l,vc](\marginparsep,0pt)
},
}

\DeclareQuestionClass{textbook}{textbooks}

\SetupExSheets{
  headings = fancy,
  question/print = true ,
  solution/print = true }
 % counter-format = se.qu ,
%  counter-within = section ,
  %question/pre-hook = \rule{\textwidth}{1pt},


\hypersetup{
	colorlinks = true, 
	breaklinks = true, 
	bookmarks = true,
	bookmarksnumbered = true,
	urlcolor = blue, 
	linkcolor = blue, 
	citecolor=blue,
	linktoc=page, 
	pdftitle={}, 
	pdfauthor={\textcopyright Author}, 
	pdfsubject={}, 
	pdfkeywords={}, 
	pdfcreator={pdfLaTeX}, % PDF Creator
	pdfproducer={IEEE} }


\makeatletter
\@addtoreset{question}{section}
\makeatother


\begin{document}
\author{Asem Alaa}

\title{Data Compression (Fall 2017):\\ second-order Markov Information Gain}

\maketitle

\begin{question}
If you have a second-order Markov sequence, where $X_n$ depends on both $X_{n-1}$ \& $X_{n-2}$
\begin{enumerate}
\item How much information about $X_n$ do you gain, if you have information about $X_{n-1}$?
\item How much information about $X_n$ do you gain, if you have information about $X_{n-1}$ \& $X_{n-2}$?
\end{enumerate}
\end{question}
\begin{solution}
Assuming that we have $M$ states, we can derive the following entropy estimations for zero-, first-, and second-order Markov model. \\
For zero-order Markov Entropy: \\
\begin{equation}
\begin{aligned}
H_0 &= - \sum_{i=1}^{M} p_i\log(p_i)
\end{aligned}
\end{equation}

For first-order Markov Entropy: \\
\begin{equation}
\begin{aligned}
H_1 &= \sum_{i=1}^{M} p_i H_i \\
H_i &= - \sum_{j=1}^{M} p_{j|i} \log( p_{j|i} ) \\
H_1 &= - \sum_{i=1}^{M} p_i \sum_{j=1}^{M} p_{j|i} \log( p_{j|i} ) 
\end{aligned}
\end{equation}

For second-order Markov Entropy: \\ 
\begin{equation}
\begin{aligned}
H_2 &= \sum_{i=1}^{M} p_i H_i \\
H_i &= \sum_{j=1}^{M} p_{j|i} H_{j|i}  \\
H_{j|i} &= - \sum_{k=1}^{M} p_{k|j,i} \log( p_{k|j,i} ) \\
H_2 &= - \sum_{i=1}^{M} p_i \sum_{j=1}^{M} p_{j|i} \sum_{k=1}^{M} p_{k|j,i} \log( p_{k|j,i} )
\end{aligned}
\end{equation}

\begin{enumerate}
\item The information gained obtained given information of $X_{n-1}$ is estimated as \\ 
\begin{equation}
\begin{aligned}
\Delta_1 &= H_0 - H_1 \\
 &= \sum_{i=1}^{M} p_i \sum_{j=1}^{M} p_{j|i} \log( p_{j|i})-\sum_{i=1}^{M} p_i\log(p_i)   \\
 &= \sum_{i=1}^{M} p_i[\sum_{j=1}^{M} p_{j|i} \log( p_{j|i} ) - \log(p_i)]
\end{aligned}
\end{equation}
\item The information gained obtained given information of $X_{n-1} \&X_{n-2}$ is estimated as \\ 
\begin{equation}
\begin{aligned}
\Delta_2 &= H_0 - H_2 \\
 &= \sum_{i=1}^{M} p_i \sum_{j=1}^{M} p_{j|i} \sum_{k=1}^{M} p_{k|j,i} \log( p_{k|j,i} ) -\sum_{i=1}^{M} p_i\log(p_i)   \\
 &= \sum_{i=1}^{M} p_i[\sum_{j=1}^{M} p_{j|i} \sum_{k=1}^{M} p_{k|j,i} \log( p_{k|j,i} ) - \log(p_i)]
\end{aligned}
\end{equation}

\end{enumerate}
\end{solution}


\end{document}

